# Chapter 1: Introduction to Big Data and Big Data Engineering

In today’s digital world, data is generated at an unprecedented scale. In this chapter, we introduce the concepts of Big Data and Big Data Engineering, laying the foundation for understanding the challenges and techniques that underpin modern data-intensive applications. We also outline how these ideas merge with data science practices—especially when dealing with complex, heterogeneous datasets in real-world scenarios.

------

## What is Big Data Engineering?

**Big Data Engineering** refers to the development, implementation, and maintenance of systems and processes that collect, move, manipulate, and manage raw data to produce high-quality, consistent information. This information then supports a range of downstream use cases, including analytics, visualization, and machine learning.

Two key definitions in the field provide useful perspectives:

> **"Data engineering is all about the movement, manipulation, and management of data."**
> — Lewis Gavin, *"What is Data Engineering?"*, O'Reilly, 2020

> **"Data engineering is the development, implementation, and maintenance of systems and processes that take in raw data and produce high-quality, consistent information that supports downstream use cases, such as analysis and machine learning. Data engineering is the intersection of security, data management, DataOps, data architecture, orchestration, and software engineering."**
> — Joe Reis & Matt Housley, *"Fundamentals of Data Engineering"*, O'Reilly, 2022

In simpler terms, a **Data Engineer** is someone who collects, maintains, tests, manages, and provides access to (large) datasets, typically within an organization. As Data Science students, your goal is not necessarily to become Data Engineers, but rather to effectively handle and analyze big, complex datasets—a skill essential for any data scientist working in realistic, real-world environments.

------

## Data Engineering vs. Data Science

While Big Data Engineering and Data Science are closely related, they are distinct disciplines. A common way to illustrate this distinction is with a Venn diagram:

![](C:\HSD\OneDrive - Hochschule Düsseldorf\Books_scripts\big_data_engineering_course\images\sketch_big_data_engineering_vs_scientist_venn.png)

- Data Engineering (Infrastructure Side):
  - Involves building the systems for data ingestion, storage, and management.
  - Emphasizes infrastructure, system implementation, database administration, and orchestration.
- Data Science (Analytical Side):
  - Focuses on analyzing data, developing models, interpreting results, and visualizing findings.
  - Leverages the output of data engineering to solve analytical problems and generate insights.

In this course, we blend elements of both areas. We not only explore techniques to analyze large and complex datasets, but also cover some fundamental engineering tasks such as using databases and implementing approximate nearest neighbor algorithms. This hybrid approach prepares you to handle real-world problems where data is often large, distributed, heterogeneous, and occasionally incomplete.

------

## What is “Big Data”?

The term **Big Data** encompasses datasets that are too large, too complex, or too rapidly changing for conventional data processing methods. The following dimensions (commonly known as the 3Vs and, in some cases, the 4Vs) capture the essence of Big Data:

- **Volume:** The sheer amount of data.
- **Velocity:** The speed at which data is generated and processed.
- **Variety:** The different forms and types of data (structured, unstructured, etc.).
- **(Sometimes) Veracity/Value:** The quality and reliability of the data, and the value extracted from it.

### How Big is Big Data?

Big Data is a relative term. Consider the following comparisons and numbers:

- Scale Comparisons:
  - **Small Scale:** All of the English Wikipedia (roughly 20 GB) can fit on a USB stick.
  - **Large Scale:** High-resolution datasets, like a collection of 500,000 images, or scientific data generated by the Large Hadron Collider (CERN) amounting to approximately 20,000,000 GB per year.
- Everyday Size Analogies:
  - **2 Kilobytes (kB):** Approximately one written page.
  - **1 Megabyte (MB):** Approximately one book or novel.
  - **1 Gigabyte (GB):** About a shelf full of books.
  - **1 Terabyte (TB):** Roughly the collection in a larger library.
  - **20 TB:** Approximately all the books that exist in German (estimated around 15–20 million books).
  - **1 Petabyte (PB):** All information in major German research libraries.
  - **5 Exabytes (EB):** Roughly equivalent to all the words ever spoken.
  - **1 Zettabyte (ZB):** An almost incomprehensible volume of data.

These examples illustrate that "big" is not merely a function of the dataset’s physical size, but also its complexity and the challenges it poses to traditional processing methods.

------

## Summary

- **Big Data Engineering** is about building the robust systems required to handle, process, and serve massive datasets efficiently.
- **Data Engineering vs. Data Science:** Data engineering focuses on the infrastructure and processes for data handling, while data science is centered on extracting insights and building models from data.
- **Big Data** involves datasets that are too voluminous, complex, or fast-paced for traditional tools, necessitating advanced techniques and infrastructure.

This introductory chapter sets the stage for the rest of the course, where we will explore both the theoretical foundations and practical techniques—including hands-on coding sessions—to tackle big data challenges. The final project, for instance, will bring these concepts together by requiring you to build an efficient image recommender system that combines multiple similarity metrics, database management, and approximate nearest neighbor algorithms.